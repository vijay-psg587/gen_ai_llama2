{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDo2HLVk34b8W/U6L+ft4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fceeb218a59e43e3a3c77aece15e9472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec6374abcd70490b87cfaca43af35b5a",
              "IPY_MODEL_f5e628f8cdc04c28a2dc07e9a57de660",
              "IPY_MODEL_f2c68b5039184f469a306c1764a73ad7"
            ],
            "layout": "IPY_MODEL_6768fcdbee624ca98705d89933adcf14"
          }
        },
        "ec6374abcd70490b87cfaca43af35b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ea735a2aa6479a9273e7b7681c1d30",
            "placeholder": "​",
            "style": "IPY_MODEL_db371f2ad9af4010a502e9355a36daf4",
            "value": "model.safetensors: 100%"
          }
        },
        "f5e628f8cdc04c28a2dc07e9a57de660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328b2395a5df4afa99c44f763d6189c3",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe3cbd6646934a81a60228bf06b87e72",
            "value": 267832558
          }
        },
        "f2c68b5039184f469a306c1764a73ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c179ea0afade4affa95344380dd9b8cf",
            "placeholder": "​",
            "style": "IPY_MODEL_860ceb759186498a9432783afe063e05",
            "value": " 268M/268M [00:02&lt;00:00, 134MB/s]"
          }
        },
        "6768fcdbee624ca98705d89933adcf14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ea735a2aa6479a9273e7b7681c1d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db371f2ad9af4010a502e9355a36daf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "328b2395a5df4afa99c44f763d6189c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe3cbd6646934a81a60228bf06b87e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c179ea0afade4affa95344380dd9b8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "860ceb759186498a9432783afe063e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijay-psg587/gen_ai_llama2/blob/feature%2Fmistral/test_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the `PIPELINE` of transfomers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8nXyRi58STD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1O03hPH8Nlu",
        "outputId": "120d3f15-1ccb-41dd-ce62-7735e52912ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.7.1)\n",
            "Requirement already satisfied: python_dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.18.2)\n",
            "Collecting colorama>=0.3.9 (from icecream)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.16.1)\n",
            "Collecting executing>=0.3.1 (from icecream)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.0.1 icecream-2.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate huggingface_hub pydantic python_dotenv icecream"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained model - tokenizing, processing and post processing\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZwO353z9Bw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli  logout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv0ichlT-CYA",
        "outputId": "389fb343-54f1-4e57-9f47-580c1b741a94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not logged in!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Login to Huggingface\n"
      ],
      "metadata": {
        "id": "F2LRQQ-B-qSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the necessary Keys"
      ],
      "metadata": {
        "id": "KCEOz9w7-NCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_API_KEY\"]=\"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\"\n",
        "os.environ[\"HF_MODEL\"]= \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "\n",
        "## decoder test models\n",
        "os.environ[\"HF_DECODER_BERT_UNCASED\"]=\"bert-base-uncased\"\n",
        "os.environ[\"HF_DECODER_DISTILL_BERT_CHECKPOINT\"] = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "os.environ[\"HF_DECODER_DISTILL_BERT_FINE_TUNED\"] = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "print(os.getenv(\"HF_API_KEY\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKBjnxCl-QY-",
        "outputId": "543aaa60-edcf-479d-e6dc-1b1c6f6c0e7d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from icecream import ic\n",
        "try:\n",
        "  import huggingface_hub as hfb\n",
        "  hfb.login(token=os.getenv(\"HF_API_KEY\"), add_to_git_credential=True)\n",
        "except ValueError as ve:\n",
        "  print(\"Value error:{}\".format(str(ve)))\n",
        "except Exception as e:\n",
        "  print(f\"Common error:{str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNyqn8iP-sZR",
        "outputId": "bac524f1-9147-4c74-8637-57560748b63f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the tokenizer from Transfomer"
      ],
      "metadata": {
        "id": "2EOVys8m-1rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
        "# from transformers import TFAutoModel, PtAutoModel # these are exclusive for the respective model type to be loaded. use AutoModel which determines the model type of its own\n",
        "import os\n",
        "##Fetching the config\n",
        "config =  AutoConfig.from_pretrained(os.getenv(\"HF_DECODER_BERT_UNCASED\"));\n",
        "print(config);\n",
        "print(os.getcwd())\n",
        "# config.save_pretrained(os.path.join(os.getcwd(),\"LLM/config/BERT_UNCASED\"))\n",
        "config.save_pretrained(\"./LLM/config/BERT_UNCASED\") # this is to store in colab location\n",
        "\n",
        "## Create the tokenizer -  converting the input sequence to high dimenspace vectors\n",
        "tokenizers = AutoTokenizer.from_pretrained(os.getenv(\"HF_DECODER_DISTILL_BERT_CHECKPOINT\"))\n",
        "tokenizers.save_pretrained(\"./LLM/tokenizer/DISTILBERT\")\n",
        "\n",
        "## We also create the model from it\n",
        "model = AutoModel.from_pretrained(os.getenv(\"HF_DECODER_DISTILL_BERT_CHECKPOINT\"))\n",
        "model.save_pretrained(\"./LLM/model/DISTILBERT\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_ZBy8Kc-5YV",
        "outputId": "fe05d3cd-7072-4c3e-9ae3-2bc9b104bd3f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.40.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## THis is a sample  fpr testing\n"
      ],
      "metadata": {
        "id": "Bk0fCJ9X7VA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "import os\n",
        "\n",
        "model = TFAutoModel.from_pretrained(os.getenv(\"HF_DECODER_DISTILL_BERT_CHECKPOINT\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "fceeb218a59e43e3a3c77aece15e9472",
            "ec6374abcd70490b87cfaca43af35b5a",
            "f5e628f8cdc04c28a2dc07e9a57de660",
            "f2c68b5039184f469a306c1764a73ad7",
            "6768fcdbee624ca98705d89933adcf14",
            "e1ea735a2aa6479a9273e7b7681c1d30",
            "db371f2ad9af4010a502e9355a36daf4",
            "328b2395a5df4afa99c44f763d6189c3",
            "fe3cbd6646934a81a60228bf06b87e72",
            "c179ea0afade4affa95344380dd9b8cf",
            "860ceb759186498a9432783afe063e05"
          ]
        },
        "id": "Blf5x1IK7YHV",
        "outputId": "3c4ae2fc-f39a-4058-847f-5d044064e7e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fceeb218a59e43e3a3c77aece15e9472"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Sentiment Analysis with Decode Model - DISTILBERT"
      ],
      "metadata": {
        "id": "BeaF9PgT5cEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = [\n",
        "    \"Wow this is awesome. I love to read this book\"\n",
        "    \"The crimes created by the murky and foggy posts really trigger me\"\n",
        "]\n",
        "\n",
        "inputs = tokenizers(user_query, padding=True, truncation=True, return_tensors=\"tf\") # u can have a return value either as \"pt\" or \"tf\"\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBO1b-8l5hkM",
        "outputId": "09944d20-4bab-4480-8c66-f6807619046a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
            "array([[  101, 10166,  2023,  2003, 12476,  1012,  1045,  2293,  2000,\n",
            "         3191,  2023,  2338, 10760,  6997,  2580,  2011,  1996, 14163,\n",
            "        15952,  1998,  9666,  6292,  8466,  2428,  9495,  2033,   102]],\n",
            "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 27), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1]], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This doesnt work , probably because the return tensors are specifically given in tf and not pt\n",
        "#model = AutoModel.from_pretrained(os.getenv(\"HF_DECODER_DISTILL_BERT_FINE_TUNED\"))\n",
        "\n",
        "# So modified to load from TFAutoModel\n",
        "model = TFAutoModel.from_pretrained(os.getenv(\"HF_DECODER_DISTILL_BERT_FINE_TUNED\"))\n",
        "\n",
        "outputs = model(inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9FWyf5k5j_3",
        "outputId": "bae1acc7-db03-47a1-9ec1-0975ffc343b2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFBaseModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 27, 768), dtype=float32, numpy=\n",
            "array([[[ 0.5517104 ,  0.12487036,  0.3785873 , ...,  0.23843366,\n",
            "          1.016581  , -0.59104943],\n",
            "        [ 1.0428075 ,  0.6807785 ,  0.17305979, ...,  0.31842172,\n",
            "          1.1339669 , -0.45828193],\n",
            "        [ 0.93357354,  0.40049824,  0.27801323, ...,  0.20877199,\n",
            "          0.99516726, -0.3051931 ],\n",
            "        ...,\n",
            "        [ 0.7711765 ,  0.21543685,  0.24949251, ...,  0.17886403,\n",
            "          0.6729547 , -0.47490284],\n",
            "        [ 0.63072234,  0.19787847,  0.26493877, ...,  0.2734502 ,\n",
            "          0.98380053, -0.43003806],\n",
            "        [ 1.1915655 ,  0.40287334,  0.20719248, ...,  0.3515852 ,\n",
            "          0.47930717, -0.82283175]]], dtype=float32)>, hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    }
  ]
}